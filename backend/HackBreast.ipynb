{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ClTh  UnCeSi  UnCeSh  MaAd  SiEpCeSi  BaNu  BlCh  NoNu  Mitoses\n",
      "0       5       1       1     1         2     1     3     1        1\n",
      "1       5       4       4     5         7    10     3     2        1\n",
      "2       3       1       1     1         2     2     3     1        1\n",
      "3       6       8       8     1         3     4     3     7        1\n",
      "4       4       1       1     3         2     1     3     1        1\n",
      "5       8      10      10     8         7    10     9     7        1\n",
      "6       2       1       2     1         2     1     3     1        1\n",
      "7       4       2       1     1         2     1     2     1        1\n",
      "8       1       1       1     1         1     1     3     1        1\n",
      "9       2       1       1     1         2     1     2     1        1\n",
      "10      1       1       1     1         2     3     3     1        1\n",
      "11      8       7       5    10         7     9     5     5        4\n",
      "12      4       1       1     1         2     1     2     1        1\n",
      "13      4       1       1     1         2     1     3     1        1\n",
      "14     10       7       7     6         4    10     4     1        2\n",
      "15      6       1       1     1         2     1     3     1        1\n",
      "16      7       3       2    10         5    10     5     4        4\n",
      "17     10       5       5     3         6     7     7    10        1\n",
      "18      3       1       1     1         2     1     2     1        1\n",
      "19      1       1       1     1         2     1     3     1        1\n",
      "20      3       2       1     1         1     1     2     1        1\n",
      "21      5       1       1     1         2     1     2     1        1\n",
      "22      2       1       1     1         2     1     2     1        1\n",
      "23      1       1       3     1         2     1     1     1        1\n",
      "24      3       1       1     1         1     1     2     1        1\n",
      "25      2       1       1     1         2     1     3     1        1\n",
      "26     10       7       7     3         8     5     7     4        3\n",
      "27      2       1       1     2         2     1     3     1        1\n",
      "28      3       1       2     1         2     1     2     1        1\n",
      "29      2       1       1     1         2     1     2     1        1\n",
      "..    ...     ...     ...   ...       ...   ...   ...   ...      ...\n",
      "92      4       2       1     1         2     2     3     1        1\n",
      "93     10      10      10     2        10    10     5     3        3\n",
      "94      5       3       5     1         8    10     5     3        1\n",
      "95      5       4       6     7         9     7     8    10        1\n",
      "96      1       1       1     1         2     1     2     1        1\n",
      "97      7       5       3     7         4    10     7     5        5\n",
      "98      3       1       1     1         2     1     3     1        1\n",
      "99      8       3       5     4         5    10     1     6        2\n",
      "100     5       1       3     1         2     1     2     1        1\n",
      "101     2       1       1     1         2     1     3     1        1\n",
      "102     5      10       8    10         8    10     3     6        3\n",
      "103     3       1       1     1         2     1     2     2        1\n",
      "104     3       1       1     1         3     1     2     1        1\n",
      "105     5       1       1     1         2     2     3     3        1\n",
      "106     4       1       1     1         2     1     2     1        1\n",
      "107     3       1       1     1         2     1     1     1        1\n",
      "108     4       1       2     1         2     1     2     1        1\n",
      "109     3       1       1     1         2     1     1     1        1\n",
      "110     2       1       1     1         2     1     1     1        1\n",
      "111     1       1       1     1         2     5     1     1        1\n",
      "112     2       1       1     1         2     1     2     1        1\n",
      "113     1       1       1     1         3     2     2     1        1\n",
      "114     8       8       7     4        10    10     7     8        7\n",
      "115     1       1       1     1         1     1     3     1        1\n",
      "116     7       2       4     1         6    10     5     4        3\n",
      "117    10      10       8     6         4     5     8    10        1\n",
      "118     4       1       1     1         2     3     1     1        1\n",
      "119     1       1       1     1         2     1     1     1        1\n",
      "120     5       5       5     6         3    10     3     1        1\n",
      "121     1       2       2     1         2     1     2     1        1\n",
      "\n",
      "[122 rows x 9 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      1\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     1\n",
      "12     0\n",
      "13     0\n",
      "14     1\n",
      "15     0\n",
      "16     1\n",
      "17     1\n",
      "18     0\n",
      "19     0\n",
      "20     0\n",
      "21     0\n",
      "22     0\n",
      "23     0\n",
      "24     0\n",
      "25     0\n",
      "26     1\n",
      "27     0\n",
      "28     0\n",
      "29     0\n",
      "      ..\n",
      "92     0\n",
      "93     1\n",
      "94     1\n",
      "95     1\n",
      "96     0\n",
      "97     1\n",
      "98     0\n",
      "99     1\n",
      "100    0\n",
      "101    0\n",
      "102    1\n",
      "103    0\n",
      "104    0\n",
      "105    0\n",
      "106    0\n",
      "107    0\n",
      "108    0\n",
      "109    0\n",
      "110    0\n",
      "111    0\n",
      "112    0\n",
      "113    0\n",
      "114    1\n",
      "115    0\n",
      "116    1\n",
      "117    1\n",
      "118    0\n",
      "119    0\n",
      "120    1\n",
      "121    0\n",
      "Name: Class, Length: 122, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/neighbors/lof.py:236: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import math\n",
    "\n",
    "filename = \"breast-cancer-wisconsin.data.txt\"\n",
    "\n",
    "# Initialize datafrmae\n",
    "dataframe = pd.read_csv(filename, header=None)\n",
    "dataframe = dataframe.drop(0, 1)\n",
    "columns = ['ClTh', 'UnCeSi', 'UnCeSh', 'MaAd', 'SiEpCeSi', 'BaNu', \n",
    "           'BlCh', 'NoNu', 'Mitoses', 'Class']\n",
    "dataframe.columns = columns\n",
    "\n",
    "# Clean out missing values\n",
    "dataframe = dataframe[dataframe.BaNu != '?']\n",
    "dataframe = dataframe.reset_index(drop=True)\n",
    "dataframe = dataframe.astype(int)\n",
    "\n",
    "# Clean out outliers\n",
    "LOF = LocalOutlierFactor(n_neighbors = 200)\n",
    "Local = LOF.fit_predict(dataframe.drop(['Class'], axis=1))\n",
    "dataframe['LOF_det'] = Local\n",
    "\n",
    "# Drop outlier column \n",
    "dataframe = dataframe[dataframe.LOF_det != -1]\n",
    "dataframe = dataframe.drop(['LOF_det'], axis=1)\n",
    "dataframe = dataframe.reset_index(drop=True)\n",
    "\n",
    "# Change class values from 4,2 to 1,0\n",
    "dataframe['Class'] = dataframe['Class'].replace(4, 1)\n",
    "dataframe['Class'] = dataframe['Class'].replace(2, 0)\n",
    "\n",
    "# Split data 80-20\n",
    "len_data = len(dataframe.index)\n",
    "len_split = math.ceil(len_data * 0.8)\n",
    "dataTest = dataframe.head(len_data - len_split)\n",
    "dataTrain = dataframe.head(len_split)\n",
    "\n",
    "# Get X and Y Data\n",
    "X_train = dataTrain.drop('Class', 1)\n",
    "Y_train = dataTrain.Class\n",
    "X_test = dataTest.drop('Class', 1)\n",
    "Y_test = dataTest.Class\n",
    "\n",
    "print(X_test)\n",
    "print(Y_test)\n",
    "\n",
    "# print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9836065573770492"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, Y_train)\n",
    "# scores = cross_val_score(LogReg, X_train.values, Y_train.values, 5)\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "LogReg.score(X_test.values, Y_test.values)\n",
    "\n",
    "# x_sample = X_data.iloc[3].values\n",
    "# x_sample = x_sample.reshape(1, -1)\n",
    "# print(x_sample)\n",
    "# print(LogReg.predict(x_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 3)                 30        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 46\n",
      "Trainable params: 46\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 492 samples, validate on 122 samples\n",
      "Epoch 1/80\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3981 - acc: 0.8862 - val_loss: 0.2139 - val_acc: 0.9672\n",
      "Epoch 2/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.1494 - acc: 0.9736 - val_loss: 0.1378 - val_acc: 0.9672\n",
      "Epoch 3/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.1103 - acc: 0.9756 - val_loss: 0.0987 - val_acc: 0.9836\n",
      "Epoch 4/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0976 - acc: 0.9715 - val_loss: 0.0779 - val_acc: 0.9836\n",
      "Epoch 5/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0772 - acc: 0.9837 - val_loss: 0.0874 - val_acc: 0.9754\n",
      "Epoch 6/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0726 - acc: 0.9817 - val_loss: 0.0664 - val_acc: 0.9836\n",
      "Epoch 7/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0719 - acc: 0.9837 - val_loss: 0.0657 - val_acc: 0.9836\n",
      "Epoch 8/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0685 - acc: 0.9837 - val_loss: 0.0647 - val_acc: 0.9836\n",
      "Epoch 9/80\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0665 - acc: 0.9797 - val_loss: 0.0776 - val_acc: 0.9836\n",
      "Epoch 10/80\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0717 - acc: 0.9858 - val_loss: 0.0603 - val_acc: 0.9836\n",
      "Epoch 11/80\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0625 - acc: 0.9858 - val_loss: 0.0600 - val_acc: 0.9836\n",
      "Epoch 12/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0629 - acc: 0.9817 - val_loss: 0.0594 - val_acc: 0.9836\n",
      "Epoch 13/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0637 - acc: 0.9817 - val_loss: 0.0772 - val_acc: 0.9836\n",
      "Epoch 14/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0632 - acc: 0.9817 - val_loss: 0.0579 - val_acc: 0.9836\n",
      "Epoch 15/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0577 - acc: 0.9797 - val_loss: 0.0611 - val_acc: 0.9836\n",
      "Epoch 16/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0578 - acc: 0.9837 - val_loss: 0.0570 - val_acc: 0.9836\n",
      "Epoch 17/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0612 - acc: 0.9817 - val_loss: 0.0691 - val_acc: 0.9836\n",
      "Epoch 18/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0584 - acc: 0.9858 - val_loss: 0.0496 - val_acc: 0.9836\n",
      "Epoch 19/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0634 - acc: 0.9817 - val_loss: 0.0651 - val_acc: 0.9836\n",
      "Epoch 20/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0555 - acc: 0.9837 - val_loss: 0.0495 - val_acc: 0.9836\n",
      "Epoch 21/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0578 - acc: 0.9837 - val_loss: 0.0499 - val_acc: 0.9836\n",
      "Epoch 22/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0558 - acc: 0.9858 - val_loss: 0.0527 - val_acc: 0.9836\n",
      "Epoch 23/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0511 - acc: 0.9878 - val_loss: 0.0483 - val_acc: 0.9836\n",
      "Epoch 24/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0551 - acc: 0.9858 - val_loss: 0.0468 - val_acc: 0.9836\n",
      "Epoch 25/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0544 - acc: 0.9858 - val_loss: 0.0535 - val_acc: 0.9836\n",
      "Epoch 26/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0530 - acc: 0.9858 - val_loss: 0.0540 - val_acc: 0.9836\n",
      "Epoch 27/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0528 - acc: 0.9837 - val_loss: 0.0504 - val_acc: 0.9836\n",
      "Epoch 28/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0578 - acc: 0.9837 - val_loss: 0.0502 - val_acc: 0.9836\n",
      "Epoch 29/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0518 - acc: 0.9858 - val_loss: 0.0554 - val_acc: 0.9836\n",
      "Epoch 30/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0554 - acc: 0.9858 - val_loss: 0.0485 - val_acc: 0.9836\n",
      "Epoch 31/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0519 - acc: 0.9858 - val_loss: 0.0611 - val_acc: 0.9836\n",
      "Epoch 32/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0541 - acc: 0.9837 - val_loss: 0.0507 - val_acc: 0.9836\n",
      "Epoch 33/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0570 - acc: 0.9837 - val_loss: 0.0468 - val_acc: 0.9836\n",
      "Epoch 34/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0544 - acc: 0.9858 - val_loss: 0.0588 - val_acc: 0.9836\n",
      "Epoch 35/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0504 - acc: 0.9837 - val_loss: 0.0651 - val_acc: 0.9836\n",
      "Epoch 36/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0539 - acc: 0.9858 - val_loss: 0.0450 - val_acc: 0.9836\n",
      "Epoch 37/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0505 - acc: 0.9878 - val_loss: 0.0448 - val_acc: 0.9836\n",
      "Epoch 38/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0501 - acc: 0.9858 - val_loss: 0.0493 - val_acc: 0.9836\n",
      "Epoch 39/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0494 - acc: 0.9878 - val_loss: 0.0511 - val_acc: 0.9836\n",
      "Epoch 40/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0508 - acc: 0.9878 - val_loss: 0.0453 - val_acc: 0.9836\n",
      "Epoch 41/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0475 - acc: 0.9878 - val_loss: 0.0485 - val_acc: 0.9836\n",
      "Epoch 42/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0500 - acc: 0.9878 - val_loss: 0.0437 - val_acc: 0.9836\n",
      "Epoch 43/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0502 - acc: 0.9878 - val_loss: 0.0445 - val_acc: 0.9836\n",
      "Epoch 44/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0514 - acc: 0.9837 - val_loss: 0.0503 - val_acc: 0.9836\n",
      "Epoch 45/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0501 - acc: 0.9878 - val_loss: 0.0433 - val_acc: 0.9836\n",
      "Epoch 46/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0460 - acc: 0.9858 - val_loss: 0.0542 - val_acc: 0.9836\n",
      "Epoch 47/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0485 - acc: 0.9878 - val_loss: 0.0433 - val_acc: 0.9836\n",
      "Epoch 48/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0430 - acc: 0.9898 - val_loss: 0.0519 - val_acc: 0.9836\n",
      "Epoch 49/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0523 - acc: 0.9858 - val_loss: 0.0517 - val_acc: 0.9836\n",
      "Epoch 50/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0515 - acc: 0.9878 - val_loss: 0.0428 - val_acc: 0.9836\n",
      "Epoch 51/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0490 - acc: 0.9878 - val_loss: 0.0417 - val_acc: 0.9836\n",
      "Epoch 52/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0450 - acc: 0.9878 - val_loss: 0.0418 - val_acc: 0.9836\n",
      "Epoch 53/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0471 - acc: 0.9878 - val_loss: 0.0482 - val_acc: 0.9836\n",
      "Epoch 54/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0491 - acc: 0.9878 - val_loss: 0.0528 - val_acc: 0.9836\n",
      "Epoch 55/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0473 - acc: 0.9858 - val_loss: 0.0420 - val_acc: 0.9836\n",
      "Epoch 56/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0469 - acc: 0.9878 - val_loss: 0.0441 - val_acc: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0488 - acc: 0.9878 - val_loss: 0.0433 - val_acc: 0.9836\n",
      "Epoch 58/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0472 - acc: 0.9878 - val_loss: 0.0478 - val_acc: 0.9836\n",
      "Epoch 59/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0535 - acc: 0.9817 - val_loss: 0.0462 - val_acc: 0.9836\n",
      "Epoch 60/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0458 - acc: 0.9878 - val_loss: 0.0462 - val_acc: 0.9836\n",
      "Epoch 61/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0480 - acc: 0.9858 - val_loss: 0.0478 - val_acc: 0.9836\n",
      "Epoch 62/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0530 - acc: 0.9858 - val_loss: 0.0428 - val_acc: 0.9836\n",
      "Epoch 63/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0468 - acc: 0.9878 - val_loss: 0.0440 - val_acc: 0.9836\n",
      "Epoch 64/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0484 - acc: 0.9878 - val_loss: 0.0444 - val_acc: 0.9836\n",
      "Epoch 65/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0489 - acc: 0.9837 - val_loss: 0.0543 - val_acc: 0.9836\n",
      "Epoch 66/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0490 - acc: 0.9878 - val_loss: 0.0500 - val_acc: 0.9836\n",
      "Epoch 67/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0492 - acc: 0.9878 - val_loss: 0.0433 - val_acc: 0.9836\n",
      "Epoch 68/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0467 - acc: 0.9878 - val_loss: 0.0453 - val_acc: 0.9836\n",
      "Epoch 69/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0501 - acc: 0.9878 - val_loss: 0.0467 - val_acc: 0.9836\n",
      "Epoch 70/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0457 - acc: 0.9858 - val_loss: 0.0437 - val_acc: 0.9836\n",
      "Epoch 71/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0470 - acc: 0.9878 - val_loss: 0.0427 - val_acc: 0.9836\n",
      "Epoch 72/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0482 - acc: 0.9878 - val_loss: 0.0447 - val_acc: 0.9836\n",
      "Epoch 73/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0432 - acc: 0.9878 - val_loss: 0.0423 - val_acc: 0.9836\n",
      "Epoch 74/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0450 - acc: 0.9878 - val_loss: 0.0416 - val_acc: 0.9836\n",
      "Epoch 75/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0566 - acc: 0.9817 - val_loss: 0.0515 - val_acc: 0.9836\n",
      "Epoch 76/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0467 - acc: 0.9858 - val_loss: 0.0674 - val_acc: 0.9836\n",
      "Epoch 77/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0447 - acc: 0.9898 - val_loss: 0.0441 - val_acc: 0.9836\n",
      "Epoch 78/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0498 - acc: 0.9858 - val_loss: 0.0425 - val_acc: 0.9836\n",
      "Epoch 79/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0470 - acc: 0.9878 - val_loss: 0.0416 - val_acc: 0.9836\n",
      "Epoch 80/80\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.0459 - acc: 0.9878 - val_loss: 0.0419 - val_acc: 0.9836\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=9, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "fitModel = model.fit(X_train.values, Y_train.values, batch_size=1, epochs=80, \n",
    "                      validation_data=(X_test.values, Y_test.values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "acc: 98.36%\n",
      "[[1.22107e-06]]\n",
      "[[0.867795]]\n",
      "[[0.0005451]]\n",
      "[[0.84610283]]\n",
      "[[4.0255668e-07]]\n",
      "[[0.99848026]]\n",
      "[[0.00016248]]\n",
      "[[2.223473e-05]]\n",
      "[[0.00012745]]\n",
      "[[3.169132e-05]]\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "loaded_score = loaded_model.evaluate(X_test.values, Y_test.values)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], loaded_score[1]*100))\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(loaded_model.predict(X_test.values[i].reshape(1,-1), batch_size=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age menopause tumor-size inv-nodes node-caps  deg-malig breast  \\\n",
      "0    40-49   premeno      15-19       0-2       yes          3  right   \n",
      "1    50-59      ge40      15-19       0-2        no          1  right   \n",
      "2    50-59      ge40      35-39       0-2        no          2   left   \n",
      "3    40-49   premeno      35-39       0-2       yes          3  right   \n",
      "4    40-49   premeno      30-34       3-5       yes          2   left   \n",
      "5    50-59   premeno      25-29       3-5        no          2  right   \n",
      "6    50-59      ge40      40-44       0-2        no          3   left   \n",
      "7    40-49   premeno      10-14       0-2        no          2   left   \n",
      "8    40-49   premeno        0-4       0-2        no          2  right   \n",
      "9    40-49      ge40      40-44     15-17       yes          2  right   \n",
      "10   50-59   premeno      25-29       0-2        no          2   left   \n",
      "11   60-69      ge40      15-19       0-2        no          2  right   \n",
      "12   50-59      ge40      30-34       0-2        no          1  right   \n",
      "13   50-59      ge40      25-29       0-2        no          2  right   \n",
      "14   40-49   premeno      25-29       0-2        no          2   left   \n",
      "15   30-39   premeno      20-24       0-2        no          3   left   \n",
      "16   50-59   premeno      10-14       3-5        no          1  right   \n",
      "17   60-69      ge40      15-19       0-2        no          2  right   \n",
      "18   50-59   premeno      40-44       0-2        no          2   left   \n",
      "19   50-59      ge40      20-24       0-2        no          3   left   \n",
      "20   50-59      lt40      20-24       0-2       NaN          1   left   \n",
      "21   60-69      ge40      40-44       3-5        no          2  right   \n",
      "22   50-59      ge40      15-19       0-2        no          2  right   \n",
      "23   40-49   premeno      10-14       0-2        no          1  right   \n",
      "24   30-39   premeno      15-19       6-8       yes          3   left   \n",
      "25   50-59      ge40      20-24       3-5       yes          2  right   \n",
      "26   50-59      ge40      10-14       0-2        no          2  right   \n",
      "27   40-49   premeno      10-14       0-2        no          1  right   \n",
      "28   60-69      ge40      30-34       3-5       yes          3   left   \n",
      "29   40-49   premeno      15-19     15-17       yes          3   left   \n",
      "..     ...       ...        ...       ...       ...        ...    ...   \n",
      "256  50-59      ge40      40-44       0-2        no          2   left   \n",
      "257  60-69      ge40      25-29       0-2        no          3   left   \n",
      "258  40-49   premeno      30-34       3-5       yes          2  right   \n",
      "259  50-59      ge40      20-24       0-2        no          2   left   \n",
      "260  70-79      ge40      20-24       0-2        no          3   left   \n",
      "261  30-39   premeno      25-29       0-2        no          1   left   \n",
      "262  60-69      ge40      30-34       0-2        no          2   left   \n",
      "263  40-49   premeno      20-24       3-5       yes          2  right   \n",
      "264  50-59      ge40      30-34      9-11       NaN          3   left   \n",
      "265  50-59      ge40        0-4       0-2        no          2   left   \n",
      "266  40-49   premeno      20-24       0-2        no          3  right   \n",
      "267  30-39   premeno      35-39       0-2        no          3   left   \n",
      "268  60-69      ge40      30-34       0-2        no          1   left   \n",
      "269  60-69      ge40      20-24       0-2        no          1   left   \n",
      "270  50-59      ge40      25-29       6-8        no          3   left   \n",
      "271  50-59   premeno      35-39     15-17       yes          3  right   \n",
      "272  30-39   premeno      20-24       3-5       yes          2  right   \n",
      "273  40-49   premeno      20-24       6-8        no          2  right   \n",
      "274  50-59      ge40      35-39       0-2        no          3   left   \n",
      "275  50-59   premeno      35-39       0-2        no          2  right   \n",
      "276  40-49   premeno      25-29       0-2        no          2   left   \n",
      "277  40-49   premeno      35-39       0-2        no          2  right   \n",
      "278  50-59   premeno      30-34       3-5       yes          2   left   \n",
      "279  40-49   premeno      20-24       0-2        no          2  right   \n",
      "280  60-69      ge40      15-19       0-2        no          3  right   \n",
      "281  50-59      ge40      30-34       6-8       yes          2   left   \n",
      "282  50-59   premeno      25-29       3-5       yes          2   left   \n",
      "283  30-39   premeno      30-34       6-8       yes          2  right   \n",
      "284  50-59   premeno      15-19       0-2        no          2  right   \n",
      "285  50-59      ge40      40-44       0-2        no          3   left   \n",
      "\n",
      "    breast-quad irradiat                 Class  \n",
      "0       left_up       no     recurrence-events  \n",
      "1       central       no  no-recurrence-events  \n",
      "2      left_low       no     recurrence-events  \n",
      "3      left_low      yes  no-recurrence-events  \n",
      "4      right_up       no     recurrence-events  \n",
      "5       left_up      yes  no-recurrence-events  \n",
      "6       left_up       no  no-recurrence-events  \n",
      "7       left_up       no  no-recurrence-events  \n",
      "8     right_low       no  no-recurrence-events  \n",
      "9       left_up      yes  no-recurrence-events  \n",
      "10     left_low       no  no-recurrence-events  \n",
      "11      left_up       no  no-recurrence-events  \n",
      "12      central       no  no-recurrence-events  \n",
      "13      left_up       no  no-recurrence-events  \n",
      "14     left_low      yes     recurrence-events  \n",
      "15      central       no  no-recurrence-events  \n",
      "16      left_up       no  no-recurrence-events  \n",
      "17      left_up       no  no-recurrence-events  \n",
      "18      left_up       no  no-recurrence-events  \n",
      "19      left_up       no  no-recurrence-events  \n",
      "20     left_low       no     recurrence-events  \n",
      "21      left_up      yes  no-recurrence-events  \n",
      "22     left_low       no  no-recurrence-events  \n",
      "23      left_up       no  no-recurrence-events  \n",
      "24     left_low      yes     recurrence-events  \n",
      "25      left_up       no  no-recurrence-events  \n",
      "26     left_low       no  no-recurrence-events  \n",
      "27      left_up       no  no-recurrence-events  \n",
      "28     left_low       no  no-recurrence-events  \n",
      "29     left_low       no     recurrence-events  \n",
      "..          ...      ...                   ...  \n",
      "256    left_low       no  no-recurrence-events  \n",
      "257   right_low      yes     recurrence-events  \n",
      "258    left_low       no  no-recurrence-events  \n",
      "259     left_up       no     recurrence-events  \n",
      "260     left_up       no  no-recurrence-events  \n",
      "261     central       no  no-recurrence-events  \n",
      "262    left_low       no  no-recurrence-events  \n",
      "263    right_up      yes     recurrence-events  \n",
      "264    left_low      yes  no-recurrence-events  \n",
      "265     central       no  no-recurrence-events  \n",
      "266    left_low      yes  no-recurrence-events  \n",
      "267    left_low       no     recurrence-events  \n",
      "268     left_up       no  no-recurrence-events  \n",
      "269    left_low       no  no-recurrence-events  \n",
      "270    left_low      yes     recurrence-events  \n",
      "271    right_up       no     recurrence-events  \n",
      "272     left_up      yes  no-recurrence-events  \n",
      "273    left_low      yes  no-recurrence-events  \n",
      "274    left_low       no  no-recurrence-events  \n",
      "275     left_up       no  no-recurrence-events  \n",
      "276     left_up      yes  no-recurrence-events  \n",
      "277    right_up       no  no-recurrence-events  \n",
      "278    left_low      yes  no-recurrence-events  \n",
      "279    right_up       no  no-recurrence-events  \n",
      "280     left_up      yes  no-recurrence-events  \n",
      "281    left_low       no  no-recurrence-events  \n",
      "282    left_low      yes  no-recurrence-events  \n",
      "283    right_up       no  no-recurrence-events  \n",
      "284    left_low       no  no-recurrence-events  \n",
      "285    right_up       no  no-recurrence-events  \n",
      "\n",
      "[286 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# filename2 = \"breast-cancer_csv.csv\"\n",
    "\n",
    "# # Initialize datafrmae\n",
    "# dataframe2 = pd.read_csv(filename2, header=0)\n",
    "# # dataframe = dataframe.drop(0, 1)\n",
    "# # columns = []\n",
    "# # dataframe.columns = columns\n",
    "\n",
    "# print(dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
